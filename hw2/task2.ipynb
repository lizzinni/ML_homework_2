{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 2\n",
    "Используйте kernel trick для классификации графов с помощью ridge регрессии (она используется для регрессии, но здесь мы сделаем вид, что все ок, и будем обрубать значения меньше 0 и больше 1) и svm (в Sklearn можно использовать кастомные kernels).\n",
    "Датасеты отсюда: https://github.com/FilippoMB/Benchmark_dataset_for_graph_classification\n",
    "Ядра можно взять отсюда: https://github.com/ysig/GraKeL\n",
    "Подберите лучшее ядро для всех случаев."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from grakel import GraphKernel, graph_from_networkx\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:42:00.678848Z",
     "start_time": "2024-12-12T22:42:00.671703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Хотим изменить все значения так, чтобы они были из промежутка [0, 1]\n",
    "def clip_values(arr):\n",
    "    arr = np.array(arr)\n",
    "    return np.clip(arr, 0, 1)\n",
    "\n",
    "# Проверяем, что данные ок\n",
    "def is_valid_data(arr):\n",
    "    arr = np.array(arr)\n",
    "    return not (np.isnan(arr).any() or np.isinf(arr).any())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:42:01.667053Z",
     "start_time": "2024-12-12T22:42:01.660932Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# загружаем данные из датасета hard_small, тк на датасете hard все алгоритмы очень долго работают\n",
    "# поскольку в нем очень много значений\n",
    "\n",
    "# загружаю данные по официальному примеру с репы grakel\n",
    "loaded = np.load('hard_small.npz', allow_pickle=True)\n",
    "A_train = list(loaded['tr_adj'])\n",
    "X_train = loaded['tr_feat']\n",
    "y_train = loaded['tr_class']\n",
    "A_test = list(loaded['te_adj'])\n",
    "X_test = loaded['te_feat']\n",
    "y_test = loaded['te_class']\n",
    "\n",
    "# Проверяем данные на валидность\n",
    "X_train = [clip_values(x) for x in X_train if is_valid_data(x)]\n",
    "X_test = [clip_values(x) for x in X_test if is_valid_data(x)]\n",
    "\n",
    "# Конвертация в формат networkx также по примеру кода из репы grakel\n",
    "G_tr = []\n",
    "for a, x in zip(A_train, X_train):\n",
    "    G = nx.from_scipy_sparse_array(a)\n",
    "    x_tuple = tuple(map(tuple, x))\n",
    "    nx.set_node_attributes(G, dict(enumerate(x_tuple)), 'features')\n",
    "    G_tr.append(G)\n",
    "\n",
    "G_te = []\n",
    "for a, x in zip(A_test, X_test):\n",
    "    G = nx.from_scipy_sparse_array(a)\n",
    "    x_tuple = tuple(map(tuple, x))\n",
    "    nx.set_node_attributes(G, dict(enumerate(x_tuple)), 'features')\n",
    "    G_te.append(G)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:42:02.797629Z",
     "start_time": "2024-12-12T22:42:02.546136Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "G_train = graph_from_networkx(G_tr, node_labels_tag='features')\n",
    "G_train = [g for g in G_train]\n",
    "y_train = np.argmax(y_train, axis=-1)\n",
    "G_test = graph_from_networkx(G_te, node_labels_tag='features')\n",
    "G_test = [g for g in G_test]\n",
    "y_test = np.argmax(y_test, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:42:04.568463Z",
     "start_time": "2024-12-12T22:42:04.567051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "kernel_names = [\n",
    "    \"shortest_path\",\n",
    "    \"graphlet_sampling\",\n",
    "    \"pyramid_match\",\n",
    "    \"svm_theta\",\n",
    "    \"neighborhood_hash\",\n",
    "    \"subtree_wl\",\n",
    "    \"odd_sth\",\n",
    "    \"propagation\",\n",
    "    \"vertex_histogram\",\n",
    "    \"weisfeiler_lehman\",\n",
    "    \"core_framework\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:42:05.684919Z",
     "start_time": "2024-12-12T22:42:05.679002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortest_path -- Accuracy: 0.6923076923076923  time 2.8 s\n",
      "graphlet_sampling -- Accuracy: 0.38461538461538464  time 13.04 s\n",
      "pyramid_match -- Accuracy: 0.23076923076923078  time 0.98 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/grakel/kernels/kernel.py:202: RuntimeWarning: invalid value encountered in divide\n",
      "  return km / np.sqrt(np.outer(self._X_diag, self._X_diag))\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/grakel/kernels/kernel.py:167: RuntimeWarning: invalid value encountered in divide\n",
      "  km /= np.sqrt(np.outer(Y_diag, X_diag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущено ядро svm_theta из-за некорректных значений в матрице ядра.\n",
      "neighborhood_hash -- Accuracy: 0.6923076923076923  time 1.09 s\n",
      "subtree_wl -- Accuracy: 0.15384615384615385  time 0.0 s\n",
      "odd_sth -- Accuracy: 0.4230769230769231  time 8.21 s\n",
      "propagation -- Accuracy: 0.5384615384615384  time 1.06 s\n",
      "vertex_histogram -- Accuracy: 0.15384615384615385  time 0.01 s\n",
      "weisfeiler_lehman -- Accuracy: 0.7307692307692307  time 23.0 s\n",
      "core_framework -- Accuracy: 0.6923076923076923  time 5.7 s\n"
     ]
    }
   ],
   "source": [
    "for k_ in kernel_names:  # просто перебираем все ядра\n",
    "    try:\n",
    "        start = time()\n",
    "        if k_ in [\"weisfeiler_lehman\", \"core_framework\"]:\n",
    "            gk = GraphKernel(kernel=[{\"name\": k_}, {\"name\": \"shortest_path\"}], normalize=True)\n",
    "\n",
    "        else:\n",
    "            gk = GraphKernel(kernel=[{\"name\": k_}], normalize=True)\n",
    "\n",
    "        K_train = gk.fit_transform(G_train)\n",
    "        K_test = gk.transform(G_test)\n",
    "        if not is_valid_data(K_train) or not is_valid_data(K_test):\n",
    "            print(f\"Пропущено ядро {k_} из-за некорректных значений в матрице ядра.\")\n",
    "            continue\n",
    "        clf = svm.SVC(kernel='precomputed', C=1)\n",
    "        clf.fit(K_train, y_train)\n",
    "        y_pred = clf.predict(K_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        end = time()\n",
    "        print(k_, \"-- Accuracy:\", acc, \" time\",\n",
    "              str(round(end - start, 2)), \"s\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке ядра {k_}: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:43:03.042992Z",
     "start_time": "2024-12-12T22:42:06.593995Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что самые лучшие результаты выдает weisfeiler_lehman, но он работает дольше всего, в соотношении время - качество, лучше всего работает shortest_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим, какие будут результаты у Ridge - регрессии"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shortest_path -- Accuracy: 0.4230769230769231  time 2.83 s\n",
      "graphlet_sampling -- Accuracy: 0.34615384615384615  time 11.97 s\n",
      "pyramid_match -- Accuracy: 0.34615384615384615  time 0.97 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/grakel/kernels/kernel.py:202: RuntimeWarning: invalid value encountered in divide\n",
      "  return km / np.sqrt(np.outer(self._X_diag, self._X_diag))\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/grakel/kernels/kernel.py:167: RuntimeWarning: invalid value encountered in divide\n",
      "  km /= np.sqrt(np.outer(Y_diag, X_diag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущено ядро svm_theta из-за некорректных значений в матрице ядра.\n",
      "neighborhood_hash -- Accuracy: 0.34615384615384615  time 0.88 s\n",
      "subtree_wl -- Accuracy: 0.34615384615384615  time 0.01 s\n",
      "odd_sth -- Accuracy: 0.34615384615384615  time 7.16 s\n",
      "propagation -- Accuracy: 0.34615384615384615  time 0.95 s\n",
      "vertex_histogram -- Accuracy: 0.34615384615384615  time 0.01 s\n",
      "weisfeiler_lehman -- Accuracy: 0.4230769230769231  time 21.39 s\n",
      "core_framework -- Accuracy: 0.4230769230769231  time 5.77 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# делаю то же самое, но теперь для ridge\n",
    "for k_ in kernel_names:\n",
    "    try:\n",
    "        start = time()\n",
    "        if k_ in [\"weisfeiler_lehman\", \"core_framework\"]:\n",
    "            gk = GraphKernel(kernel=[{\"name\": k_}, {\"name\": \"shortest_path\"}], normalize=True)\n",
    "\n",
    "        else:\n",
    "            gk = GraphKernel(kernel=[{\"name\": k_}], normalize=True)\n",
    "\n",
    "        K_train = gk.fit_transform(G_train)\n",
    "        K_test = gk.transform(G_test)\n",
    "\n",
    "        if not is_valid_data(K_train) or not is_valid_data(K_test):\n",
    "            print(f\"Пропущено ядро {k_} из-за некорректных значений в матрице ядра.\")\n",
    "            continue\n",
    "\n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(K_train, y_train)\n",
    "\n",
    "        y_pred = ridge.predict(K_test)\n",
    "        y_pred = clip_values(y_pred)\n",
    "        y_pred_class = np.round(y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred_class)\n",
    "        end = time()\n",
    "        print(k_, \"-- Accuracy:\", acc, \" time\",\n",
    "              str(round(end - start, 2)), \"s\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке ядра {k_}: {e}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:44:05.791386Z",
     "start_time": "2024-12-12T22:43:13.282554Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "shortest_path, core_framework, weisfeiler_lehman выдают одинаковые результаты, но быстрее всего отрабатывает shortest_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дополнительно: поэкспериментируйте с kernel construction на основе kernels из библиотеки и попробуйте предложить свой kernel, который работает лучше"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "G_train, G_test, y_train, y_test = train_test_split(G_train, y_train, test_size=0.3, random_state=42)\n",
    "# перемешиваю данные\n",
    "# без этого у меня получались подозрительно одинаковые ответы всегда, получалось accuracy = accuracy weisfeiler_lehman для svm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T22:44:57.845517Z",
     "start_time": "2024-12-12T22:44:57.842514Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "class CustomKernel:  # класс для создания собственного ядра, можно брать взвешенную сумму ядер (линейная функция)\n",
    "    # а можно брать нелинейную функцию\n",
    "    def __init__(self, normalize=True, combination='sum', weights=None):\n",
    "        self.gk1 = None\n",
    "        self.gk2 = None\n",
    "        self.gk3 = None\n",
    "        self.gk4 = None\n",
    "        self.K_train = None\n",
    "        self.normalize = normalize\n",
    "        self.combination = combination  # лк, произведение\n",
    "        self.weights = weights if weights is not None else [0.5, 0.5]\n",
    "\n",
    "    def fit_transform(self, graphs):\n",
    "        # Пробовала комбинировать kernels, которые давали лучшие результаты, но здесь сильно улучшить accuracy\n",
    "        # не получалось. В связи с этим решила попробовать взять те, у которых были результаты не очень\n",
    "        # У pyramid_match acc=0.23, у graphlet_sampling acc=0.35\n",
    "        self.gk1 = GraphKernel(kernel=[{\"name\": \"pyramid_match\"}], normalize=self.normalize)\n",
    "        self.gk2 = GraphKernel(kernel=[{\"name\": \"graphlet_sampling\"}], normalize=self.normalize)\n",
    "\n",
    "        k1 = self.gk1.fit_transform(graphs)\n",
    "        k2 = self.gk2.fit_transform(graphs)\n",
    "\n",
    "        if self.combination == 'sum':\n",
    "            # взвешенная сумма двух ядер (линейная комбинация)\n",
    "            self.K_train = self.weights[0] * k1 + self.weights[1] * k2\n",
    "        elif self.combination == 'multiply':\n",
    "            # посмотрим еще на произведение\n",
    "            self.K_train = k1 * k2\n",
    "        return self.K_train\n",
    "\n",
    "    def transform(self, graphs):\n",
    "        k1 = self.gk1.transform(graphs)\n",
    "        k2 = self.gk2.transform(graphs)\n",
    "\n",
    "        if self.combination == 'sum':\n",
    "            k_test = self.weights[0] * k1 + self.weights[1] * k2\n",
    "        elif self.combination == 'multiply':\n",
    "            k_test = k1 * k2\n",
    "        return k_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T18:55:34.887817Z",
     "start_time": "2024-12-13T18:55:34.881335Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomKernel (weights 0.1, 0.9) -- Accuracy: 0.43243243243243246  time: 11.0 s\n",
      "CustomKernel (weights 0.2, 0.8) -- Accuracy: 0.43243243243243246  time: 10.44 s\n",
      "CustomKernel (weights 0.3, 0.7) -- Accuracy: 0.4594594594594595  time: 10.37 s\n",
      "CustomKernel (weights 0.4, 0.6) -- Accuracy: 0.5  time: 10.37 s\n",
      "CustomKernel (weights 0.5, 0.5) -- Accuracy: 0.5135135135135135  time: 10.37 s\n",
      "CustomKernel (weights 0.6, 0.4) -- Accuracy: 0.5135135135135135  time: 10.36 s\n",
      "CustomKernel (weights 0.7, 0.3) -- Accuracy: 0.5  time: 10.35 s\n",
      "CustomKernel (weights 0.8, 0.2) -- Accuracy: 0.43243243243243246  time: 10.32 s\n",
      "CustomKernel (weights 0.9, 0.1) -- Accuracy: 0.40540540540540543  time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "# Попробуем подобрать лучшие значения весов + посмотреть, как меняется accuracy\n",
    "# при изменении весов\n",
    "try:\n",
    "    for w1 in np.arange(0.1, 1.0, 0.1):\n",
    "        w2 = 1.0 - round(w1, 1)\n",
    "        start = time()  # чтобы засечь время работы\n",
    "        custom_kernel = CustomKernel(normalize=True, combination='sum', weights=[w1, w2])\n",
    "        K_train_custom = custom_kernel.fit_transform(G_train)\n",
    "        K_test_custom = custom_kernel.transform(G_test)\n",
    "\n",
    "        if not is_valid_data(K_train_custom) or not is_valid_data(K_test_custom):\n",
    "            print(f\"Пропущено ядро (веса {w1}, {w2}) из-за некорректных значений в матрице.\")\n",
    "            continue\n",
    "\n",
    "        clf = svm.SVC(kernel='precomputed', C=1, class_weight='balanced')  # вот здесь оказалось, что обязательно\n",
    "        # надо добавлять class_weight='balanced' для правильного распределения данных\n",
    "        clf.fit(K_train_custom, y_train)\n",
    "        y_pred_custom = clf.predict(K_test_custom)\n",
    "        acc_custom = accuracy_score(y_test, y_pred_custom)\n",
    "        end = time()\n",
    "        print(f\"CustomKernel (weights {round(w1, 2)}, {round(w2, 2)}) -- Accuracy: {acc_custom}  time: {round(end - start, 2)} s\") # округляю все, чтобы был красивый вывод,\n",
    "        # тк в питоне float операции дают неточные ответы (знаем, что 0,1+0,2=0,30000000000000004)\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T18:57:18.448199Z",
     "start_time": "2024-12-13T18:55:44.462729Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Среди линейных комбинаций с различными весами лучшие результаты получаются, когда берем веса (сначала вес pyramid_match, потом вес graphlet_sampling) 0.5, 0.5; 0.6, 0.4 (результаты получаются одинаковыми, тк svm не чувствителен к небольшим изменениям в матрице ядра, то есть если матрицы имеют схожие значения, то эти веса будут давать похожие ответы.\n",
    "С увеличением веса pyramid_match accuracy_score растет до веса=0.6, потом начинает падать\n",
    "Это может быть связано с тем, что при резкой разнице между весами ядер у нас одно доминирует над другим, то есть (по крайней мере при крайних значениях) мы почти полностью игнорируем одно из ядер.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomKernel (multiply) -- Accuracy: 0.5405405405405406  time 10.4 s\n"
     ]
    }
   ],
   "source": [
    "# считаем accuracy для произведения ядер\n",
    "try:\n",
    "    start = time()  # чтобы засечь время работы\n",
    "    custom_kernel = CustomKernel(normalize=True, combination='multiply')\n",
    "    K_train_custom = custom_kernel.fit_transform(G_train)\n",
    "    K_test_custom = custom_kernel.transform(G_test)\n",
    "\n",
    "    if not is_valid_data(K_train_custom) or not is_valid_data(K_test_custom):\n",
    "        print(\"Пропущено из-за некорректных значений в матрице.\")\n",
    "    else:\n",
    "        clf = svm.SVC(kernel='precomputed', C=1, class_weight='balanced')\n",
    "        clf.fit(K_train_custom, y_train)\n",
    "        y_pred_custom = clf.predict(K_test_custom)\n",
    "        acc_custom = accuracy_score(y_test, y_pred_custom)\n",
    "        end = time()\n",
    "        print(\"CustomKernel (multiply) -- Accuracy:\", acc_custom, \" time\", str(round(end - start, 2)), \"s\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T18:58:46.162683Z",
     "start_time": "2024-12-13T18:58:35.763026Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для pyramid_match и graphlet_sampling лучше всего получается результат, когда берем не линейную комбинацию ядер, а произведение. Это связано с тем, что произведение ядер усиливает сходства, то есть мы особенно сильно смотрим на области, где оба ядра pyramid_match и graphlet_sampling дают сильный сигнал. Если у нас есть какие-то сложные связи в графах, то поэтому может быть лучший результат у произведения."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "По времени они все работают примерно одинаково, но дольше чем каждое ядро, взятое по отдельности.\n",
    "Это связано с тем, что надо вычислять несколько ядер, а также с тем, что мы тратим время на операции на комбинирование + нормализацию"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class LogKernel:\n",
    "    def __init__(self, normalize=True, weights=None):\n",
    "        self.normalize = normalize  # нормализация\n",
    "        self.weights = weights if weights is not None else [0.5, 0.5]  # по дефолту веса по 1/2\n",
    "\n",
    "    def fit_transform_pair(self, graphs, gk1, gk2):\n",
    "        # преобразуем обучающую выборку\n",
    "        k1 = gk1.fit_transform(graphs)\n",
    "        k2 = gk2.fit_transform(graphs)\n",
    "        return self.weights[0] * np.log(k1) + self.weights[1] * np.log(k2)  # логарифмическое ядро\n",
    "\n",
    "    def transform_pair(self, graphs, gk1, gk2):\n",
    "        # преобразуем тестовую выборку\n",
    "        k1 = gk1.transform(graphs)\n",
    "        k2 = gk2.transform(graphs)\n",
    "        return self.weights[0] * np.log(k1) + self.weights[1] * np.log(k2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T19:28:55.467053Z",
     "start_time": "2024-12-13T19:28:55.458553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Kernel Pair (pyramid_match, graphlet_sampling) -- Accuracy: 0.5405405405405406  time: 10.55 s\n",
      "Log Kernel Pair (pyramid_match, weisfeiler_lehman) -- Accuracy: 0.47297297297297297  time: 11.59 s\n",
      "Log Kernel Pair (pyramid_match, shortest_path) -- Accuracy: 0.5675675675675675  time: 14.82 s\n",
      "Log Kernel Pair (graphlet_sampling, weisfeiler_lehman) -- Accuracy: 0.44594594594594594  time: 24.86 s\n",
      "Log Kernel Pair (graphlet_sampling, shortest_path) -- Accuracy: 0.5945945945945946  time: 37.35 s\n",
      "Log Kernel Pair (weisfeiler_lehman, shortest_path) -- Accuracy: 0.5945945945945946  time: 40.24 s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    start = time()  # замеряем время\n",
    "    kernel_names = [\"pyramid_match\", \"graphlet_sampling\", \"weisfeiler_lehman\", \"shortest_path\"]\n",
    "    # проинициализируем ядра\n",
    "    kernels = [GraphKernel(kernel=[{\"name\": name}], normalize=True) for name in kernel_names]\n",
    "\n",
    "    log_kernel = LogKernel(normalize=True)\n",
    "\n",
    "    for i in range(len(kernels)):\n",
    "        for j in range(i + 1, len(kernels)):  # хотим перебрать все пары из 4х\n",
    "            gk1, gk2 = kernels[i], kernels[j]\n",
    "            kernel1, kernel2 = kernel_names[i], kernel_names[j]\n",
    "\n",
    "            K_train_custom = log_kernel.fit_transform_pair(G_train, gk1, gk2)\n",
    "            K_test_custom = log_kernel.transform_pair(G_test, gk1, gk2)\n",
    "\n",
    "            if not is_valid_data(K_train_custom) or not is_valid_data(K_test_custom):\n",
    "                print(f\"Пропущено ядро для ({kernel1}, {kernel2}) из-за некорректных значений.\")\n",
    "                continue\n",
    "\n",
    "            clf = svm.SVC(kernel='precomputed', C=1, class_weight='balanced')\n",
    "            clf.fit(K_train_custom, y_train)  # обучаем\n",
    "            y_pred_custom = clf.predict(K_test_custom)  # предиктим\n",
    "            acc_custom = accuracy_score(y_test, y_pred_custom)  # считаем скор\n",
    "            end = time()\n",
    "\n",
    "            print(f\"Log Kernel Pair ({kernel1}, {kernel2}) -- Accuracy: {acc_custom}  time: {round(end - start, 2)} s\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T19:29:38.109476Z",
     "start_time": "2024-12-13T19:28:57.858902Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Заметим, что результаты не сильно улучшились по сравнению с ядрами без модификаций. Логарифмические ядра, где участвует weisfeiler_lehman выдают не очень хорошие результаты, тк мы делаем сильную редукцию значений, а для weisfeiler_lehman, например, важно, чтобы были различия в значениях. Поэтому, выгоднее брать это ядро в комбинациях, которые не делают сглаживания значений. Также я брала в комбинации ядра с не очень хорошим скором изначально, например у pyramid_match был результат всего 0.23, хотя в комбинации, например с shortest_path результат стал получше (shortest_path улучшил pyramid_match, но у shortest_path без модификаций результат выше)\n",
    "\n",
    "Однако логарифмическое ядро для пары (pyramid_match, graphlet_sampling) дает лучший результат (0,54), чем они по отдельности 0,23 и 0,39"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Скорость стала медленнее, тк помимо всего прочего нам надо считать по 2 логарифма для каждой комбинации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# делаем то же самое, что и для логарифмического, только теперь экспонента, структура класса такая же\n",
    "class ExpKernel:\n",
    "    def __init__(self, normalize=True, weights=None):\n",
    "        self.normalize = normalize  # Нормализация ядер\n",
    "        self.weights = weights if weights is not None else [0.5, 0.5]\n",
    "\n",
    "    def fit_transform_pair(self, graphs, gk1, gk2):\n",
    "        k1 = gk1.fit_transform(graphs)\n",
    "        k2 = gk2.fit_transform(graphs)\n",
    "        return np.exp(self.weights[0] * k1 + self.weights[1] * k2)\n",
    "\n",
    "    def transform_pair(self, graphs, gk1, gk2):\n",
    "        k1 = gk1.transform(graphs)\n",
    "        k2 = gk2.transform(graphs)\n",
    "        return np.exp(self.weights[0] * k1 + self.weights[1] * k2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T19:38:02.694740Z",
     "start_time": "2024-12-13T19:38:02.689579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp Kernel Pair (pyramid_match, graphlet_sampling) -- Accuracy: 0.5135135135135135  time: 10.76 s\n",
      "Exp Kernel Pair (pyramid_match, weisfeiler_lehman) -- Accuracy: 0.4864864864864865  time: 11.8 s\n",
      "Exp Kernel Pair (pyramid_match, shortest_path) -- Accuracy: 0.6216216216216216  time: 15.04 s\n",
      "Exp Kernel Pair (graphlet_sampling, weisfeiler_lehman) -- Accuracy: 0.43243243243243246  time: 25.25 s\n",
      "Exp Kernel Pair (graphlet_sampling, shortest_path) -- Accuracy: 0.6351351351351351  time: 38.25 s\n",
      "Exp Kernel Pair (weisfeiler_lehman, shortest_path) -- Accuracy: 0.6216216216216216  time: 41.25 s\n"
     ]
    }
   ],
   "source": [
    "# выводим резы для экспоненциального ядра, такая же логика как для логарифмического\n",
    "try:\n",
    "    start = time()\n",
    "    exp_kernel = ExpKernel(normalize=True)\n",
    "\n",
    "    for i in range(len(kernels)):\n",
    "        for j in range(i + 1, len(kernels)):\n",
    "            gk1, gk2 = kernels[i], kernels[j]\n",
    "            kernel1, kernel2 = kernel_names[i], kernel_names[j]\n",
    "\n",
    "            K_train_custom = exp_kernel.fit_transform_pair(G_train, gk1, gk2)\n",
    "            K_test_custom = exp_kernel.transform_pair(G_test, gk1, gk2)\n",
    "\n",
    "            if not is_valid_data(K_train_custom) or not is_valid_data(K_test_custom):\n",
    "                print(f\"Пропущено ядро для ({kernel1}, {kernel2}) из-за некорректных значений.\")\n",
    "                continue\n",
    "\n",
    "            clf = svm.SVC(kernel='precomputed', C=1, class_weight='balanced')\n",
    "            clf.fit(K_train_custom, y_train)\n",
    "            y_pred_custom = clf.predict(K_test_custom)\n",
    "            acc_custom = accuracy_score(y_test, y_pred_custom)\n",
    "            end = time()\n",
    "\n",
    "            print(f\"Exp Kernel Pair ({kernel1}, {kernel2}) -- Accuracy: {acc_custom}  time: {round(end - start, 2)} s\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T19:38:45.865034Z",
     "start_time": "2024-12-13T19:38:04.611982Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Скорость ниже по тем же причинам, что и у логарифмического\n",
    "Опять же, улучшился результат только для пары (pyramid_match, graphtlet_sampling)\n",
    "В остальном у нас weisfeiler_lehman все еще дает лучший результат без модификаций\n",
    "Экспоненциальное ядро усиливает различия между значениями, поэтому у нас могут быть не очень хорошие результаты для ядер, которые чувствительны к большим перепадам в значениях. И, наоборот, экспоненциальное ядро дает лучший результат для ядер, которые лучше работают, когда есть различия между значениями\n",
    "Все пары с shortest_path выдают результат > 0.62, поскольку shortest_path выдавал нам хороший результат и без модификаций, сейчас скор стал чуть хуже, но shortest_path улучшает accuracy для всех остальных ядер"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Хочется проверить предположение о том, что ядра, которые выдают лучший результат при наличии больших различий между данными будут выдавать лучший скор с экспоненциальным ядром\n",
    "Для этого посмотрю на экспоненциальное ядро для pyramid_match"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36486486486486486  time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "exp_kernel = ExpKernel(normalize=True)\n",
    "\n",
    "gk1 = GraphKernel(kernel=[{\"name\": \"pyramid_match\"}], normalize=True)\n",
    "\n",
    "K_train_custom = exp_kernel.fit_transform_pair(G_train, gk1, gk1)\n",
    "K_test_custom = exp_kernel.transform_pair(G_test, gk1, gk1)\n",
    "\n",
    "if not is_valid_data(K_train_custom) or not is_valid_data(K_test_custom):\n",
    "    print(\"Пропущено из-за некорректных значений.\")\n",
    "else:\n",
    "    clf = svm.SVC(kernel='precomputed', C=1, class_weight='balanced')\n",
    "    clf.fit(K_train_custom, y_train)\n",
    "    y_pred_custom = clf.predict(K_test_custom)\n",
    "    acc_custom = accuracy_score(y_test, y_pred_custom)\n",
    "    end = time()\n",
    "\n",
    "    print(f\"Accuracy: {acc_custom}  time: {round(end - start, 2)} s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T19:54:24.158815Z",
     "start_time": "2024-12-13T19:54:22.635713Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как видно результат и правда улучшился по сравнению с просто pyramid_match\n",
    "Это произошло, тк pyramid_match работает хорошо, если у графов есть сходства в структуре или подграфах или если различия между графами одного класса малы, а различия между классами велики\n",
    "\n",
    "При использовании экспоненциального ядра сходства усиливаются, а несходства наоборот, тк экспоненциальное ядро усиливает различия, то есть разделение на классы становится четче\n",
    "Предположение оказалось правдой\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
