{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 1\n",
    "Реализуйте непараметрический LDA (лекция 2, слайд 34). Возьмите датасеты из предыдущего ДЗ (3 задание) (если не делали, подберите или сгенерируйте) и попытайтесь побить затюненный регуляризованный LDA (если не делали предыдущее задание, или ваша реализация получилась неудачной, то можете взять реализацию из sklearn), подбирая kernel (перебирайте популярные, а также попробуйте придумать свой kernel), lambda (можно подбирать константу, а можно функцию, лекция 2 - слайд 26). Сравните время работы алгоритмов."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KernelDensity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T20:12:49.765442Z",
     "start_time": "2024-12-13T20:12:49.064827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class NonparametricLDA:\n",
    "    def __init__(self, kernel='gaussian', bandwidth=1.0, lam=0.01):\n",
    "        self.kernel = kernel\n",
    "        self.bandwidth = bandwidth\n",
    "        self.lam = lam\n",
    "        self.density = []  # Список KDE для каждого класса\n",
    "        self.priors = None  # Априорные вероятности классов\n",
    "        self.n = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.n = len(np.unique(y_train))\n",
    "        self.priors = self.estimate_class_priors(y_train)\n",
    "        self.density = []\n",
    "        for i in range(self.n):\n",
    "            X_i = X_train[np.where(y_train == i)[0]]\n",
    "            if X_i.shape[0] == 0:  # Проверяем, есть ли данные для данного класса\n",
    "                # без этой проверки все падает с ошибкой ValueError\n",
    "                self.density.append(None)\n",
    "                continue\n",
    "            kde = self.estimate_density(X_i)\n",
    "            self.density.append(kde)\n",
    "\n",
    "\n",
    "    def predict(self, X_test):  # по формулам со слайда\n",
    "        ln_probs = []\n",
    "        for i in range(self.n):\n",
    "            if self.density[i] is None:  # Если KDE для класса отсутствует\n",
    "                ln_probs.append(-np.inf * np.ones(X_test.shape[0]))\n",
    "                continue\n",
    "            ln_priors = np.log(self.priors[i])  # log(pi_l / pi_j)\n",
    "            ln_density = self.density[i].score_samples(X_test if X_test.ndim > 1 else X_test[:, np.newaxis])\n",
    "            # log плотностей\n",
    "            ln_probs.append(ln_priors + ln_density)\n",
    "        ln_probs = np.array(ln_probs).T\n",
    "        return np.argmax(ln_probs, axis=1)\n",
    "\n",
    "\n",
    "    def estimate_density(self, X):  # для оценки плотности\n",
    "        kde = KernelDensity(kernel=self.kernel, bandwidth=self.bandwidth).fit(X)\n",
    "        return kde\n",
    "\n",
    "    def estimate_class_priors(self, y):\n",
    "        y = np.array(y)\n",
    "        prior = np.array([(y == i).mean() for i in np.unique(y)])\n",
    "        # для того чтобы посчитать log(pi_l / pi_j)\n",
    "        # надо посчитать априорные вероятности классов,\n",
    "        # у нас pi_i = число объектов в классе i / общее число объектов\n",
    "        return prior"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T20:13:39.496405Z",
     "start_time": "2024-12-13T20:13:39.484186Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def tune(X_train, y_train, X_test, y_test):\n",
    "    kernels = ['gaussian', 'tophat', 'epanechnikov', 'cosine', 'linear', 'exponential']\n",
    "\n",
    "    bandwidths = np.linspace(0.1, 2.0, 10)\n",
    "    lambdas = np.logspace(-3.0, 0.0, 20)\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    for k in kernels:\n",
    "        for l in lambdas:\n",
    "            for b in bandwidths:\n",
    "                model = NonparametricLDA(kernel=k, lam=l, bandwidth=b)\n",
    "                try:\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds = model.predict(X_test)\n",
    "                    score = accuracy_score(y_test, preds)\n",
    "                    if best_score < score:\n",
    "                        best_score = score\n",
    "                        best_params = {\"k\": k, \"l\": l, \"b\": b}\n",
    "                except ValueError as e:\n",
    "                    print(f\"Ошибка: {e}. Пропускаем эти параметры.\")\n",
    "    return best_score, best_params\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T20:21:49.190766Z",
     "start_time": "2024-12-13T20:21:49.183820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "# грузим те же датасеты, что и в дз1 таска 3\n",
    "def load_mushroom():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df = df.apply(LabelEncoder().fit_transform)\n",
    "    X = df.iloc[:, 1:].values\n",
    "    y = df.iloc[:, 0].values  # 0: съедобный, 1: ядовитый\n",
    "    return X, y\n",
    "\n",
    "def load_ecoli():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/ecoli/ecoli.data\"\n",
    "    df = pd.read_csv(url, delim_whitespace=True, header=None)\n",
    "    X = df.iloc[:, 1:-1].values\n",
    "    y = LabelEncoder().fit_transform(df.iloc[:, -1].values)\n",
    "    return X, y\n",
    "\n",
    "def load_glass():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\"\n",
    "    column_names = [\n",
    "        'id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'type'\n",
    "    ]\n",
    "    df = pd.read_csv(url, header=None, names=column_names)\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values  # тип стекла\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T20:14:43.241018Z",
     "start_time": "2024-12-13T20:14:42.681117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(as_frame=True),\n",
    "    \"Wine\": load_wine(as_frame=True),\n",
    "    \"Breast Cancer\": load_breast_cancer(as_frame=True),\n",
    "    \"Ecoli\": load_ecoli(),\n",
    "    \"Mushroom\": load_mushroom(),\n",
    "    \"Glass\": load_glass()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T20:16:13.336344Z",
     "start_time": "2024-12-13T20:16:09.909458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dataset     Score                                        Best Params\n",
      "0           Iris  0.966667            {'k': 'gaussian', 'l': 0.001, 'b': 0.1}\n",
      "1           Wine  1.000000  {'k': 'exponential', 'l': 0.001, 'b': 1.155555...\n",
      "2  Breast Cancer  0.964912  {'k': 'gaussian', 'l': 0.001, 'b': 0.944444444...\n",
      "3          Ecoli  0.926471  {'k': 'cosine', 'l': 0.001, 'b': 1.36666666666...\n",
      "4       Mushroom  1.000000  {'k': 'gaussian', 'l': 0.001, 'b': 0.311111111...\n",
      "5          Glass  0.581395         {'k': 'exponential', 'l': 0.001, 'b': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "results = []\n",
    "scaler = StandardScaler()\n",
    "for dataset_name, data in datasets.items():\n",
    "    if isinstance(data, tuple):\n",
    "        X, y = data\n",
    "    else:\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "\n",
    "    # Преобразуем X и y в массивы (если они не являются массивами)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Разделение на тренировочную и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Настройка гиперпараметров\n",
    "    best_score, best_params = tune(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Создание и обучение модели с лучшими параметрами\n",
    "    model = NonparametricLDA(kernel=best_params[\"k\"], lam=best_params[\"l\"], bandwidth=best_params[\"b\"])\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Сохранение результатов\n",
    "    results.append({\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Score\": accuracy_score(y_test, predictions),\n",
    "        \"Best Params\": best_params,\n",
    "    })\n",
    "\n",
    "# Вывод результатов в виде таблицы\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T20:26:48.401853Z",
     "start_time": "2024-12-13T20:21:52.953756Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для начала про подобранные параметры: сначала я выбирала lambda из более маленького промежутка и заметила, что лучшим параметром всегда является левая граница промежутка. Я решила увеличить промежуток, а также использовать вместо np.linspace - np.logspace (создает числа равномерно распределенные, причем в логарифмическом масштабе и 20 штук, до этого делала 10 и в линейном масштабе), но тенденция сохранилась, все еще лучшей лямбдой считается левая граница промежутка значений лямбд.\n",
    "Это в целом объяснимо тем, что с уменьшением лямбды модель становится более гибкой, также, я посмотрела, датасеты не очень большие сами по себе, шума в них почти нет, поэтому выгодно брать маленькие лямбды. Также, вероятно, классы хорошо разделимы, значит маленькой лямбды нам хватает\n",
    "\n",
    "## Теперь сравним с результатами задачи 3 из дз1\n",
    "В предыдущем дз я получала такие результаты:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dataset   rLDA LogReg\n",
      "0  Breast Cancer  0.974  0.974\n",
      "1          Ecoli  0.809  0.882\n",
      "2          Glass  0.744  0.721\n",
      "3           Iris  1.000  1.000\n",
      "4       Mushroom  0.945  0.966\n",
      "5           Wine  1.000  1.000\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [\"Iris\", \"1.000\", \"1.000\"],\n",
    "        [\"Wine\", \"1.000\", \"1.000\"],\n",
    "        [\"Breast Cancer\", \"0.974\", \"0.974\"],\n",
    "        [\"Ecoli\", \"0.809\", \"0.882\"],\n",
    "        [\"Mushroom\", \"0.945\", \"0.966\"],\n",
    "        [\"Glass\", \"0.744\", \"0.721\"]\n",
    "    ],\n",
    "    columns=[\"Dataset\", \"rLDA\", \"LogReg\"]\n",
    ")\n",
    "res = (df\n",
    "       .pivot_table(index=[\"Dataset\", \"rLDA\", \"LogReg\"], fill_value=0)\n",
    "       .reset_index()\n",
    "       )\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T20:59:43.749554Z",
     "start_time": "2024-12-13T20:59:43.742636Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что для Wine результаты совпадают, для Iris, Breast Cancer почти совпадают (различия незначительны), для датасета Glass результат непараметрического LDA сильно хуже, поскольку этот датасет маленький, а непараметрический лда сильно зависит от плотности данных, то есть, поскольку датасет маленький, у нас получаются очень неточные оценки (шум), поэтому качество непараметрического лда здесь страдает\n",
    "Для датасетов Ecoli, Mushroom лучше работает непараметрический лда"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Кастомное ядро\n",
    "Я хотела сделать его на базе класса, который реализовала выше, но я там использую KernelDensity, которая не кушает кастомные ядра, поэтому, чтобы не терять результаты работы, я сделаю еще класс на основе https://scikit-learn.org/1.5/modules/generated/sklearn.gaussian_process.kernels.Kernel.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process.kernels import Kernel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T13:55:55.095515Z",
     "start_time": "2024-12-14T13:55:55.004036Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class CustomKernel(Kernel):  # по примеру из https://scikit-learn.org/1.5/modules/generated/sklearn.gaussian_process.kernels.Kernel.html\n",
    "    def __init__(self, bandwidth=1.0):\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "    def __call__(self, X, Y=None):\n",
    "        gaussian_component = pairwise_kernels(X, Y, metric='rbf', gamma=1 / (2 * self.bandwidth**2))\n",
    "        tophat_component = pairwise_kernels(X, Y, metric='cosine')\n",
    "        return 0.7 * gaussian_component + 0.3 * tophat_component\n",
    "\n",
    "    def diag(self, X):\n",
    "        return np.ones(X.shape[0])\n",
    "\n",
    "    def is_stationary(self):\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T13:56:43.029918Z",
     "start_time": "2024-12-14T13:56:43.020878Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "class NonParamLDAck: # класс для реализации непараметрического лда, чтобы было совместимо с кастомным ядром\n",
    "    # отличается от того, который был выше только отсутствием estimate_density\n",
    "    # в остальном все аналогично\n",
    "    def __init__(self, kernel, bandwidth=1.0, lam=0.01):\n",
    "        self.kernel = kernel\n",
    "        self.bandwidth = bandwidth\n",
    "        self.lam = lam\n",
    "        self.density = []\n",
    "        self.priors = None\n",
    "        self.n = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.n = len(np.unique(y_train))\n",
    "        self.priors = self.estimate_class_priors(y_train)\n",
    "        self.density = []\n",
    "        for i in range(self.n):\n",
    "            X_i = X_train[np.where(y_train == i)[0]]\n",
    "            if X_i.shape[0] == 0:  # если пустой класс, чтобы не было ошибки\n",
    "                self.density.append(None)\n",
    "                continue\n",
    "            self.density.append(X_i)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        ln_probs = []\n",
    "        for i in range(self.n):\n",
    "            if self.density[i] is None:\n",
    "                ln_probs.append(-np.inf * np.ones(X_test.shape[0]))\n",
    "                continue\n",
    "            ln_priors = np.log(self.priors[i])\n",
    "            kernel_matrix = self.kernel(X_test, self.density[i])\n",
    "            kernel_means = np.mean(kernel_matrix, axis=1)\n",
    "            kernel_means = np.where(kernel_means > 0, kernel_means, 1e-10)  # избегаем log(0), тк он не определен,\n",
    "            # поэтому меняем все неположительные значения в kernel_means на маленький положительный эпсилон\n",
    "            ln_density = np.log(kernel_means)\n",
    "            ln_probs.append(ln_priors + ln_density)\n",
    "        ln_probs = np.array(ln_probs).T\n",
    "        return np.argmax(ln_probs, axis=1)\n",
    "\n",
    "    def estimate_class_priors(self, y):\n",
    "        y = np.array(y)\n",
    "        prior = np.array([(y == i).mean() for i in np.unique(y)])\n",
    "        return prior"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T14:01:56.444019Z",
     "start_time": "2024-12-14T14:01:56.433953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Iris\": load_iris(as_frame=True),\n",
    "    \"Wine\": load_wine(as_frame=True),\n",
    "    \"Breast Cancer\": load_breast_cancer(as_frame=True),\n",
    "    \"Ecoli\": load_ecoli(),\n",
    "    \"Mushroom\": load_mushroom(),\n",
    "    \"Glass\": load_glass()\n",
    "}\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "results = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T14:02:33.073479Z",
     "start_time": "2024-12-14T14:02:29.670414Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def tune_hyperparameters(X_train, y_train, X_test, y_test):  # как и выше была функция tune, только тут мы\n",
    "    # используем custom kernel\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    bandwidths = [0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "    for bw in bandwidths:\n",
    "        kernel = CustomKernel(bandwidth=bw)\n",
    "        model = NonParamLDAck(kernel=kernel, bandwidth=bw, lam=0.01)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        score = accuracy_score(y_test, preds)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = {\"bandwidth\": bw}\n",
    "\n",
    "    return best_score, best_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T14:04:13.644937Z",
     "start_time": "2024-12-14T14:04:13.642816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "for dataset_name, data in datasets.items():\n",
    "    if isinstance(data, tuple):\n",
    "        X, y = data\n",
    "    else:\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # подбор гиперпараметров\n",
    "    best_score, best_params = tune_hyperparameters(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # тренируем с лучшими параметрами\n",
    "    kernel = CustomKernel(bandwidth=best_params[\"bandwidth\"])\n",
    "    model = NonParamLDAck(kernel=kernel, bandwidth=best_params[\"bandwidth\"], lam=0.01)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    results.append({\"Dataset\": dataset_name, \"Custom Kernel\": score, \"Best Params\": best_params})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T14:05:18.511520Z",
     "start_time": "2024-12-14T14:05:17.545001Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dataset  Custom Kernel         Best Params\n",
      "0           Iris       0.833333  {'bandwidth': 0.5}\n",
      "1           Wine       0.944444  {'bandwidth': 0.5}\n",
      "2  Breast Cancer       0.929825  {'bandwidth': 0.5}\n",
      "3          Ecoli       0.882353  {'bandwidth': 1.0}\n",
      "4       Mushroom       0.877538  {'bandwidth': 2.0}\n",
      "5          Glass       0.418605  {'bandwidth': 1.0}\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T14:05:42.169891Z",
     "start_time": "2024-12-14T14:05:42.167030Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты почти такие же, чуть похуже, тк для каждого из датасетов нам надо подбирать свое кастомное ядро, которое будет выдавать лучшие результаты, но на это, к сожалению, уйдет слишком много времени"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дополнительно: реализуйте также local likelihood logistic regression (слайды 27 и 33 из второй лекции в помощь) и сравните с моделями из основной части."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_wine, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T22:58:37.576203Z",
     "start_time": "2024-12-13T22:58:37.575234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class LocalLikelihoodLogisticRegression:\n",
    "    def __init__(self, bandwidth):\n",
    "        self.beta = None\n",
    "        self.y = None\n",
    "        self.X = None\n",
    "        self.bandwidth = bandwidth  # параметр ядра (ширина полосы пропускания)\n",
    "\n",
    "    def kernel_weights(self, x0, X):\n",
    "        # используем ядро для вычисления весов согласно формуле K_lambda(x_0, x_i)\n",
    "        dists = np.linalg.norm(X - x0, axis=1)\n",
    "        weights = np.exp(-0.5 * (dists / self.bandwidth) ** 2)  # гауссово\n",
    "        return weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict_proba(self, x0):\n",
    "        # Вычисляем веса на основе ядра\n",
    "        weights = self.kernel_weights(x0, self.X)\n",
    "\n",
    "        # Определяем локальное правдоподобие по формуле для l(beta(x_0))\n",
    "        def neg_log_likelihood(beta):\n",
    "            logits = np.clip(self.X @ beta, -500, 500)  # без такого ограничения при запуске сыпались runtime warning, тк переполнение\n",
    "            probs = 1 / (1 + np.exp(-logits))  # sigma(logits) — вероятность принадлежности к классу 1\n",
    "            ll = weights * (self.y * np.log(probs + 1e-8) + (1 - self.y) * np.log(1 - probs + 1e-8))\n",
    "            return -np.sum(ll)  # отрицательное правдоподобие для минимизации\n",
    "\n",
    "        # оптимизируем кфы (beta) по min_beta -l(beta(x_0))\n",
    "        initial_beta = np.zeros(self.X.shape[1])\n",
    "        result = minimize(neg_log_likelihood, initial_beta, method=\"BFGS\")\n",
    "        self.beta = result.x\n",
    "\n",
    "        # возвращаем вероятность для точки x0\n",
    "        logits = np.clip(x0 @ self.beta, -500, 500)  # чтобы не было переполнения\n",
    "        prob = 1 / (1 + np.exp(-logits))\n",
    "        return prob\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # предсказываем метки для каждой точки в тестовом наборе\n",
    "        predictions = []\n",
    "        for x0 in X_test:\n",
    "            prob = self.predict_proba(x0)\n",
    "            predictions.append(1 if prob >= 0.5 else 0)  # классифицируем\n",
    "        return np.array(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T23:03:16.114392Z",
     "start_time": "2024-12-13T23:03:16.108992Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def tune_params(X_train, y_train, X_test, y_test, bandwidths):  # для подбора параметров\n",
    "    best_bandwidth = None\n",
    "    best_score = 0\n",
    "\n",
    "    for bandwidth in bandwidths:\n",
    "        model = LocalLikelihoodLogisticRegression(bandwidth=bandwidth)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        score = accuracy_score(y_test, preds)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_bandwidth = bandwidth\n",
    "\n",
    "    return best_bandwidth, best_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T23:14:50.461195Z",
     "start_time": "2024-12-13T23:14:50.454306Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris in process\n",
      "Iris done in 0.91 s\n",
      "Wine in process\n",
      "Wine done in 2.67 s\n",
      "Breast Cancer in process\n",
      "Breast Cancer done in 189.49 s\n",
      "Ecoli in process\n",
      "Ecoli done in 7.4 s\n",
      "Glass in process\n",
      "Glass done in 1.96 s\n",
      "Glass skipped\n",
      "         Dataset  Best Bandwidth  LLR Accuracy  Logistic Regression Accuracy\n",
      "0           Iris        0.311111      1.000000                      1.000000\n",
      "1           Wine        0.522222      1.000000                      0.974359\n",
      "2  Breast Cancer        2.000000      0.964912                      0.982456\n",
      "3          Ecoli        1.577778      1.000000                      0.984848\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "# Загрузка датасетов\n",
    "results = []\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(as_frame=True),\n",
    "    \"Wine\": load_wine(as_frame=True),\n",
    "    \"Breast Cancer\": load_breast_cancer(as_frame=True),\n",
    "    \"Ecoli\": load_ecoli(),\n",
    "    \"Glass\": load_glass()\n",
    "}\n",
    "for dataset_name, data in datasets.items():\n",
    "    print(f\"{dataset_name} in process\")\n",
    "    start_time = time()\n",
    "    if isinstance(data, tuple):\n",
    "        X, y = data\n",
    "    else:\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # для задачи бинарной классификации оставляем только 2 класса\n",
    "    if len(np.unique(y)) > 2:\n",
    "        X = X[y < 2]\n",
    "        y = y[y < 2]\n",
    "\n",
    "    # масштабируем данные\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # делим на обучающую и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # лучшие параметры\n",
    "    bandwidths = np.linspace(0.1, 2.0, 10)\n",
    "    best_bandwidth, best_score = tune_params(X_train, y_train, X_test, y_test, bandwidths)\n",
    "\n",
    "    # Обучение Local Likelihood Logistic Regression с лучшими параметрами\n",
    "    lllr = LocalLikelihoodLogisticRegression(bandwidth=best_bandwidth)\n",
    "    lllr.fit(X_train, y_train)\n",
    "    preds_lllr = lllr.predict(X_test)\n",
    "\n",
    "    # считаем accuracy_score\n",
    "    accuracy_lllr = accuracy_score(y_test, preds_lllr)\n",
    "    end_time = time()\n",
    "    print(f\"{dataset_name} done in\", str(round(end_time - start_time, 2)), \"s\")\n",
    "    # сравним с лог рег\n",
    "    if len(np.unique(y)) < 2:  # если меньше 2 классов и не сделать такую проверку, то падает с value error\n",
    "        print(f\"{dataset_name} skipped\")\n",
    "        accuracy_logreg = 'impossible to count'\n",
    "        continue\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    preds_logreg = logreg.predict(X_test)\n",
    "    accuracy_logreg = accuracy_score(y_test, preds_logreg)\n",
    "\n",
    "    results.append({\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Best Bandwidth\": best_bandwidth,\n",
    "        \"LLR Accuracy\": accuracy_lllr,\n",
    "        \"Logistic Regression Accuracy\": accuracy_logreg\n",
    "    })\n",
    "\n",
    "# Вывод результатов в виде таблицы\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T23:35:58.848059Z",
     "start_time": "2024-12-13T23:32:34.871215Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Здесь нет датасета Mushroom, тк мне стало страшно за здоровье ноута после 2х часов безрезультатного обучения на этом датасете, поэтому я решила, что с грибами связываться не стоит\n",
    "А кроме шуток это происходит, потому что в грибах 22 характеристики, поэтому на этом датасете алгоритм долго работал\n",
    "Также была пропущена логистическая регрессия для датасета glass, тк этот датасет слишком маленький, классов не хватает"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим, что результат Locallikelihood logreg лучше для каждого датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
