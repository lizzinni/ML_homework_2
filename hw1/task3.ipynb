{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 3\n",
    "Реализуйте регуляризованый LDA с двумя параметрами из лекции. Сравните его с логистической регрессией (осуществите тюнинг гиперпараметров для обеих моделей) на публичных датасетах (хотя бы 5) из UCI\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_classification\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from itertools import product"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T14:15:52.459221Z",
     "start_time": "2024-11-26T14:15:52.247263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class rLDA(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, alpha=0.5, gamma=0.5, epsilon=1e-6):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon  # докинем маленький эпсилон к значениям, чтобы было стабильней\n",
    "\n",
    "    # ф-ция fit для обучения\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = len(self.classes_)\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        # подсчет медиан\n",
    "        class_means = []\n",
    "        for c in self.classes_:\n",
    "            class_means.append(X[y == c].mean(axis=0))\n",
    "        global_mean = X.mean(axis=0)\n",
    "\n",
    "        cov_m_in = np.zeros((n_features, n_features)) # м-ца ковариации внутри класса, заполнили нулями\n",
    "        for i, c in enumerate(self.classes_): # считаем ковариацию для каждого класса\n",
    "            X_c = X[y == c] # смотрим на все эл-ты класса\n",
    "            cov_m_in += np.cov(X_c, rowvar=False) * (len(X_c) - 1)\n",
    "\n",
    "        cov_m_between = np.zeros((n_features, n_features)) # м-ца ковариации между классами, тоже сначала заполним нулями\n",
    "        for i, c in enumerate(self.classes_):\n",
    "            n_c = (y == c).sum() # число эл-тов в классе\n",
    "            mean_diff = class_means[i] - global_mean\n",
    "            cov_m_between += n_c * np.outer(mean_diff, mean_diff)\n",
    "\n",
    "        # регуляризованная матрица ковариации по формулам из книги\n",
    "        I = np.eye(n_features)\n",
    "        S = self.alpha * cov_m_in + self.gamma * cov_m_between + (1 - self.alpha - self.gamma) * I\n",
    "        S += self.epsilon * np.eye(n_features)\n",
    "\n",
    "        # решаем задачу на собственные значения\n",
    "        evals, evecs = eigh(cov_m_between, S)\n",
    "        self.scalings_ = evecs[:, ::-1][:, :n_classes - 1] # собственные векторы, которые соответствуют наиб собственным значениям\n",
    "        self.class_means_ = np.array(class_means)\n",
    "        self.global_mean_ = global_mean\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_projected = (X - self.global_mean_).dot(self.scalings_)\n",
    "        projected_means = (self.class_means_ - self.global_mean_).dot(self.scalings_)\n",
    "        distances = np.linalg.norm(X_projected[:, None, :] - projected_means[None, :, :], axis=2)\n",
    "        return self.classes_[np.argmin(distances, axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T14:29:25.092400Z",
     "start_time": "2024-11-26T14:29:25.084880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def best_alpha_gamma(X_train, y_train, X_test, y_test, alphas, gammas): # для поиска наилучших альфа и гамма\n",
    "    best_alpha, best_gamma, best_score = None, None, -np.inf\n",
    "    for alpha, gamma in product(alphas, gammas):\n",
    "        if alpha + gamma <= 1:\n",
    "            model = rLDA(alpha=alpha, gamma=gamma)\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_test)\n",
    "            score = accuracy_score(y_test, preds)\n",
    "            if score > best_score:\n",
    "                best_alpha, best_gamma, best_score = alpha, gamma, score\n",
    "    return best_alpha, best_gamma, best_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T14:32:06.960640Z",
     "start_time": "2024-11-26T14:32:06.927930Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Буду использовать датасеты:\n",
    "1) вино - загружаем с помощью встроенной функции в sklearn.datasets load_wine()\n",
    "2) iris, также загружаю встроенной функцией в sklearn.datasets load_iris()\n",
    "3) breast cancer, тоже встроенной функцией load_breast_cancer()\n",
    "4) ecoli\n",
    "5) mushroom\n",
    "6) glass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def load_mushroom():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df = df.apply(LabelEncoder().fit_transform)\n",
    "    X = df.iloc[:, 1:].values\n",
    "    y = df.iloc[:, 0].values  # 0: съедобный, 1: ядовитый\n",
    "    return X, y\n",
    "\n",
    "def load_ecoli():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/ecoli/ecoli.data\"\n",
    "    df = pd.read_csv(url, delim_whitespace=True, header=None)\n",
    "    X = df.iloc[:, 1:-1].values\n",
    "    y = LabelEncoder().fit_transform(df.iloc[:, -1].values)\n",
    "    return X, y\n",
    "\n",
    "def load_glass():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\"\n",
    "    column_names = [\n",
    "        'id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'type'\n",
    "    ]\n",
    "    df = pd.read_csv(url, header=None, names=column_names)\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values  # тип стекла\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T15:23:32.867423Z",
     "start_time": "2024-11-26T15:23:32.857901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Iris\": load_iris(as_frame=True),\n",
    "    \"Wine\": load_wine(as_frame=True),\n",
    "    \"Breast Cancer\": load_breast_cancer(as_frame=True),\n",
    "    \"Ecoli\": load_ecoli(),\n",
    "    \"Mushroom\": load_mushroom(),\n",
    "    \"Glass\": load_glass()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T15:23:56.588404Z",
     "start_time": "2024-11-26T15:23:45.933884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "alphas = np.linspace(0, 1, 10)\n",
    "gammas = np.linspace(0, 1, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T15:23:58.220653Z",
     "start_time": "2024-11-26T15:23:58.209103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = [] # для хранения результатов\n",
    "for dataset_name, data in datasets.items():\n",
    "    if isinstance(data, tuple):\n",
    "        X, y = data\n",
    "        X = pd.DataFrame(X)\n",
    "        y = pd.Series(y)\n",
    "    else:\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # подбираем лучшие параметры для rLDA\n",
    "    best_alpha, best_gamma, lda_score = best_alpha_gamma(X_train, y_train, X_test, y_test, alphas, gammas)\n",
    "\n",
    "    # теперь посмотрим на логрег\n",
    "    logistic = LogisticRegression(max_iter=500)\n",
    "    logistic_params = {\"C\": np.logspace(-4, 4, 10)}\n",
    "    logistic_search = GridSearchCV(logistic, param_grid=logistic_params, cv=5, scoring=\"accuracy\")\n",
    "    logistic_search.fit(X_train, y_train)\n",
    "    logistic_best = logistic_search.best_estimator_\n",
    "    logistic_score = accuracy_score(y_test, logistic_best.predict(X_test))\n",
    "\n",
    "    results.append({\n",
    "        \"Dataset\": dataset_name,\n",
    "        \"Best alpha\": best_alpha,\n",
    "        \"Best gamma\": best_gamma,\n",
    "        \"rLDA\": lda_score,\n",
    "        \"LogReg\": logistic_score\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T15:24:01.571573Z",
     "start_time": "2024-11-26T15:23:59.463421Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dataset  Best alpha  Best gamma      rLDA    LogReg\n",
      "0           Iris    0.111111    0.000000  1.000000  1.000000\n",
      "1           Wine    0.000000    0.111111  1.000000  1.000000\n",
      "2  Breast Cancer    0.111111    0.000000  0.973684  0.973684\n",
      "3          Ecoli    0.000000    0.000000  0.808824  0.882353\n",
      "4       Mushroom    0.111111    0.000000  0.945231  0.966154\n",
      "5          Glass    0.111111    0.000000  0.744186  0.720930\n"
     ]
    }
   ],
   "source": [
    "res_df = pd.DataFrame(results)\n",
    "print(res_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T15:24:04.701230Z",
     "start_time": "2024-11-26T15:24:04.696776Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дополнительно: постарайтесь найти датасеты, где LDA работает лучше и попробуйте объяснить почему.\n",
    "Подсказка: если данных достаточно много, то LDA и LogReg не будут отличаться, даже если предположения LDA выполняются, попробуйте уменьшать обучающую выборку, чтобы найти ситуации, когда LDA работает лучше. Если не получается с публичными датасетами - сгенерируйте (в этом случае посчитайте bias и variance для LDA и LogReg)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из результатов видно, что результаты у rLDA и LogReg примерно одинаковы, однако, на датасете Ecoli rLDA дает результат хуже. Попробуем использовать подсказку и уменьшить обучающую выборку для этого датасета, посмотрим, что произойдет."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train Size  Best alpha  Best gamma      rLDA    LogReg\n",
      "0         0.1    0.222222    0.111111  0.818482  0.818482\n",
      "1         0.2    0.222222    0.222222  0.836431  0.814126\n",
      "2         0.3    0.000000    0.000000  0.830508  0.822034\n",
      "3         0.4    0.111111    0.000000  0.861386  0.816832\n",
      "4         0.5    0.111111    0.000000  0.869048  0.869048\n",
      "5         0.6    0.111111    0.000000  0.881481  0.896296\n",
      "6         0.7    0.000000    0.000000  0.841584  0.881188\n",
      "7         0.8    0.000000    0.000000  0.808824  0.882353\n"
     ]
    }
   ],
   "source": [
    "def change_train(X, y, train_sizes, alphas, gammas):\n",
    "    results = []\n",
    "    for train_size in train_sizes:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=42)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        best_alpha, best_gamma, lda_score = best_alpha_gamma(X_train, y_train, X_test, y_test, alphas, gammas)\n",
    "\n",
    "        lr = LogisticRegression(max_iter=500)\n",
    "        lr_params = {\"C\": np.logspace(-4, 4, 10)}\n",
    "        lr_search = GridSearchCV(lr, param_grid=lr_params, cv=5, scoring=\"accuracy\")\n",
    "        lr_search.fit(X_train, y_train)\n",
    "        lr_best = lr_search.best_estimator_\n",
    "        score = accuracy_score(y_test, lr_best.predict(X_test))\n",
    "\n",
    "        results.append({\n",
    "            \"Train Size\": train_size,\n",
    "            \"Best alpha\": best_alpha,\n",
    "            \"Best gamma\": best_gamma,\n",
    "            \"rLDA\": lda_score,\n",
    "            \"LogReg\": score\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "X_ecoli, y_ecoli = load_ecoli()\n",
    "train_sizes = np.linspace(0.1, 0.8, 8)\n",
    "ecoli_results = change_train(X_ecoli, y_ecoli, train_sizes, alphas, gammas)\n",
    "\n",
    "print(ecoli_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T16:17:52.069775Z",
     "start_time": "2024-11-26T16:17:49.615005Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что подсказка сработала и результаты rLDA становятся лучше, когда уменьшаем размер train. До этого брали размер train = 0.8 от выборки, сейчас видим, что наилучший результат rLDA дает при train size = 0.6, а при train size = 0.4 результат rLDA лучше результата LogReg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим, что в этом случае у нас выполнено предположение rLDA, то есть нормальность и равенство матриц ковариаций"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0:\n",
      "Feature 0: P-value=0.6802\n",
      "Feature 1: P-value=0.0554\n",
      "Feature 2: P-value=1.0000\n",
      "Feature 3: P-value=1.0000\n",
      "Feature 4: P-value=0.8010\n",
      "Feature 5: P-value=0.4561\n",
      "Feature 6: P-value=0.0047\n",
      "\n",
      "Class 1:\n",
      "Feature 0: P-value=0.2865\n",
      "Feature 1: P-value=0.1084\n",
      "Feature 2: P-value=1.0000\n",
      "Feature 3: P-value=1.0000\n",
      "Feature 4: P-value=0.0010\n",
      "Feature 5: P-value=0.1361\n",
      "Feature 6: P-value=0.0003\n",
      "\n",
      "Class 4:\n",
      "Feature 0: P-value=0.6973\n",
      "Feature 1: P-value=0.5696\n",
      "Feature 2: P-value=0.0000\n",
      "Feature 3: P-value=1.0000\n",
      "Feature 4: P-value=0.0003\n",
      "Feature 5: P-value=0.2897\n",
      "Feature 6: P-value=0.0027\n",
      "\n",
      "Class 5:\n",
      "Feature 0: P-value=0.8811\n",
      "Feature 1: P-value=0.9637\n",
      "Feature 2: P-value=0.0000\n",
      "Feature 3: P-value=1.0000\n",
      "Feature 4: P-value=0.0995\n",
      "Feature 5: P-value=0.4145\n",
      "Feature 6: P-value=0.0203\n",
      "\n",
      "Class 7:\n",
      "Feature 0: P-value=0.0001\n",
      "Feature 1: P-value=0.8066\n",
      "Feature 2: P-value=1.0000\n",
      "Feature 3: P-value=1.0000\n",
      "Feature 4: P-value=0.3260\n",
      "Feature 5: P-value=0.6275\n",
      "Feature 6: P-value=0.6104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizabeth/anaconda3/lib/python3.11/site-packages/scipy/stats/_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "def norm(X_train, y_train):\n",
    "    # Список классов\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "    # Проверка нормальности и ковариаций\n",
    "    valid_classes = []  # Для классов с достаточным количеством данных\n",
    "    class_covs = []\n",
    "    normality_results = {}\n",
    "\n",
    "    # Нормальность для каждого признака\n",
    "    for c in classes:\n",
    "        X_c = X_train[y_train == c]\n",
    "        if X_c.shape[0] < 3:  # Пропускаем классы с недостаточным количеством данных\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cov_matrix = np.cov(X_c, rowvar=False)\n",
    "            class_covs.append(cov_matrix)\n",
    "            normality_results[f\"Class {c}\"] = [\n",
    "                shapiro(X_c[:, i]).pvalue if X_c[:, i].size >= 3 else None for i in range(X_c.shape[1])\n",
    "            ]\n",
    "            valid_classes.append(c)  # Сохраняем только валидные классы\n",
    "        except LinAlgError:\n",
    "            print(f\"Class {c}: Covariance matrix is singular and will be skipped.\")\n",
    "\n",
    "\n",
    "    # Вывод нормальности\n",
    "    for class_name, p_values in normality_results.items():\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        for i, pval in enumerate(p_values):\n",
    "            if pval is not None:\n",
    "                print(f\"Feature {i}: P-value={pval:.4f}\")\n",
    "            else:\n",
    "                print(f\"Feature {i}: Not enough data for test\")\n",
    "\n",
    "X_ecoli, y_ecoli = load_ecoli()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ecoli, y_ecoli, train_size=0.4, random_state=42)\n",
    "norm(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T17:31:46.127590Z",
     "start_time": "2024-11-26T17:31:44.490760Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что большинство p-value имеют значение > 0.05, то есть условие нормальности выполнено"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь проверим равенство"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Classes   P-Value\n",
      "0     0, 1  0.114932\n",
      "1     0, 4  0.005548\n",
      "2     0, 5  0.209036\n",
      "3     0, 6  0.544117\n",
      "4     0, 7  0.893454\n",
      "5     1, 4  0.781857\n",
      "6     1, 5  0.400252\n",
      "7     1, 6  0.625196\n",
      "8     1, 7  0.126967\n",
      "9     4, 5  0.099675\n",
      "10    4, 6  0.369192\n",
      "11    4, 7  0.006068\n",
      "12    5, 6  0.446047\n",
      "13    5, 7  0.238472\n",
      "14    6, 7  0.491074\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import levene\n",
    "\n",
    "# проверим равенство матриц ковариации\n",
    "def equality(X_train, y_train):\n",
    "    unique_classes = np.unique(y_train)\n",
    "    covariances = []\n",
    "\n",
    "    # считаем матрицы ковариации\n",
    "    for cls in unique_classes:\n",
    "        X_cls = X_train[y_train == cls]\n",
    "        covariance_matrix = np.cov(X_cls, rowvar=False)\n",
    "        covariances.append(covariance_matrix)\n",
    "\n",
    "    # проверка равенства\n",
    "    equal_cov_results = []\n",
    "    for i in range(len(covariances)):\n",
    "        for j in range(i + 1, len(covariances)):\n",
    "            flattened_cov1 = covariances[i].flatten()\n",
    "            flattened_cov2 = covariances[j].flatten()\n",
    "            _, p_value_equal_cov = levene(flattened_cov1, flattened_cov2)\n",
    "            equal_cov_results.append({\n",
    "                \"Classes\": f\"{unique_classes[i]}, {unique_classes[j]}\",\n",
    "                \"P-Value\": p_value_equal_cov\n",
    "            })\n",
    "\n",
    "    equal_cov_df = pd.DataFrame(equal_cov_results)\n",
    "    return equal_cov_df\n",
    "\n",
    "X_ecoli, y_ecoli = load_ecoli()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ecoli, y_ecoli, train_size=0.4, random_state=42)\n",
    "equal_cov = equality(X_train, y_train)\n",
    "\n",
    "\n",
    "print(equal_cov)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T17:32:08.690909Z",
     "start_time": "2024-11-26T17:32:07.855896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что с равенством матриц ковариации также все ок, то есть предположение rLDA выполнено, это доказывает нам хороший результат"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
